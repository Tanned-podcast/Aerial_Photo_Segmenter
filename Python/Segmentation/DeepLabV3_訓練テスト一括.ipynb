{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7901c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unified DeepLabV3+ training / validation / testing pipeline\n",
    "Supports: CE (with class weights), Dice, Focal losses\n",
    "- Computes class weights from train masks\n",
    "- Saves per-epoch model files (filename contains filedate_epochXX.pth)\n",
    "- Evaluates all saved epoch models on test set and selects best by test mIoU\n",
    "- Computes detailed metrics for best model and per-image CSV\n",
    "- Generates side-by-side visualizations for each test image\n",
    "- Saves training history (CSV) and plots\n",
    "- Records run time to TXT\n",
    "\n",
    "Requirements:\n",
    "- torch\n",
    "- torchvision\n",
    "- segmentation_models_pytorch (pip install segmentation-models-pytorch)\n",
    "- PIL, numpy, pandas, matplotlib\n",
    "\n",
    "Place your images and masks in folders and set `train_img_dir`, `train_mask_dir`, etc., below or pass via command-line args.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "import csv\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Please install segmentation-models-pytorch (pip install segmentation-models-pytorch)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration (default)\n",
    "# -----------------------------\n",
    "IMG_SIZE = (512, 512)  # (H, W)\n",
    "Channels = 3\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "valsplit = 0.1\n",
    "learning_rate = 1e-4\n",
    "loss_type = \"ce\"  # \"ce\" / \"dice\" / \"focal\"\n",
    "optimizer_type = \"adam\"  # adam / sgd\n",
    "gamma_focal = 2.0\n",
    "alpha_focal = None  # list or None, set after class weights computed\n",
    "\n",
    "# Data paths (set to your dataset)\n",
    "train_img_dir = \"data/train/images\"\n",
    "train_mask_dir = \"data/train/masks\"\n",
    "val_img_dir = None  # if None, split from train\n",
    "val_mask_dir = None\n",
    "test_img_dir = \"data/test/images\"\n",
    "test_mask_dir = \"data/test/masks\"\n",
    "\n",
    "# Output dirs (will include filedate)\n",
    "filedate = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "out_dir = os.path.join(\"outputs\", filedate)\n",
    "model_dir = os.path.join(out_dir, \"models\")\n",
    "viz_dir = os.path.join(out_dir, \"visualization\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "history_csv = os.path.join(out_dir, f\"history_{filedate}.csv\")\n",
    "runinfo_txt = os.path.join(out_dir, f\"runinfo_{filedate}.txt\")\n",
    "plots_dir = os.path.join(out_dir, \"plots\")\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, img_size=IMG_SIZE, transforms=None):\n",
    "        assert len(img_paths) == len(mask_paths)\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.img_size = img_size\n",
    "        # transforms for image (tensor & normalize)\n",
    "        self.transforms = transforms or T.Compose([\n",
    "            T.Resize(img_size, interpolation=Image.BILINEAR),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # mask transforms (nearest, preserve labels)\n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize(img_size, interpolation=Image.NEAREST),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "        img = self.transforms(img)\n",
    "        mask = self.mask_transform(mask)\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        # Convert {0,255} -> {0,1}\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return img, mask, os.path.basename(self.img_paths[idx])\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities: file pairing\n",
    "# -----------------------------\n",
    "\n",
    "def pair_images_and_masks(img_dir, mask_dir, img_exts=['.jpg', '.png', '.tif', '.tiff'], mask_exts=['.png']):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    for ext in img_exts:\n",
    "        imgs.extend(glob.glob(os.path.join(img_dir, f\"*{ext}\")))\n",
    "    imgs = sorted(imgs)\n",
    "    mask_map = {}\n",
    "    for ext in mask_exts:\n",
    "        for p in glob.glob(os.path.join(mask_dir, f\"*{ext}\")):\n",
    "            mask_map[os.path.splitext(os.path.basename(p))[0]] = p\n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    for p in imgs:\n",
    "        stem = os.path.splitext(os.path.basename(p))[0]\n",
    "        if stem in mask_map:\n",
    "            img_paths.append(p)\n",
    "            mask_paths.append(mask_map[stem])\n",
    "    return img_paths, mask_paths\n",
    "\n",
    "# -----------------------------\n",
    "# Class weight computation\n",
    "# -----------------------------\n",
    "\n",
    "def compute_class_weights(dataset, num_classes=2):\n",
    "    counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    for i in range(len(dataset)):\n",
    "        _, mask, _ = dataset[i]\n",
    "        mask_np = mask.numpy().ravel()\n",
    "        for c in range(num_classes):\n",
    "            counts[c] += int((mask_np == c).sum())\n",
    "    total = counts.sum()\n",
    "    freq = counts / total\n",
    "    # weight: inverse of frequency\n",
    "    weights = total / (num_classes * counts)\n",
    "    weights = weights.astype(np.float32)\n",
    "    return weights, counts, freq\n",
    "\n",
    "# -----------------------------\n",
    "# Losses\n",
    "# -----------------------------\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B,C,H,W], target: [B,H,W]\n",
    "        num_classes = logits.shape[1]\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        target_onehot = nn.functional.one_hot(target, num_classes).permute(0,3,1,2).float()\n",
    "        dims = (0,2,3)\n",
    "        intersection = torch.sum(probs * target_onehot, dims)\n",
    "        cardinality = torch.sum(probs + target_onehot, dims)\n",
    "        dice_score = (2. * intersection + self.eps) / (cardinality + self.eps)\n",
    "        loss = 1. - dice_score.mean()\n",
    "        return loss\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        if alpha is not None:\n",
    "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B,C,H,W], target: [B,H,W]\n",
    "        ce = nn.functional.cross_entropy(logits, target, reduction='none')\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pt = probs.gather(1, target.unsqueeze(1)).squeeze(1)  # [B,H,W]\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "        loss = focal_term * ce\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(logits.device)\n",
    "            at = alpha.gather(0, target.flatten()).view_as(target).to(logits.device)\n",
    "            loss = at * loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "\n",
    "def confusion_matrix_from_logits(logits, target, num_classes=2):\n",
    "    # logits: [B,C,H,W] or [B,1,H,W]\n",
    "    preds = torch.argmax(logits, dim=1).view(-1).cpu().numpy()\n",
    "    t = target.view(-1).cpu().numpy()\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for gt, pd in zip(t, preds):\n",
    "        cm[gt, pd] += 1\n",
    "    return cm\n",
    "\n",
    "\n",
    "def compute_metrics_from_cm(cm):\n",
    "    # cm: [num_classes,num_classes] where rows=gt, cols=pred\n",
    "    num_classes = cm.shape[0]\n",
    "    eps = 1e-6\n",
    "    tp = np.diag(cm).astype(float)\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    tn = cm.sum() - (tp + fp + fn)\n",
    "    # per-class IoU\n",
    "    iou = tp / (tp + fp + fn + eps)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    pixel_acc = tp.sum() / (cm.sum() + eps)\n",
    "    # per-class accuracy: tp / (tp + fn)\n",
    "    class_acc = tp / (tp + fn + eps)\n",
    "    mean_acc = np.nanmean(class_acc)\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "    return {\n",
    "        'iou_per_class': iou,\n",
    "        'mean_iou': mean_iou,\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_acc': mean_acc,\n",
    "        'precision_per_class': precision,\n",
    "        'recall_per_class': recall,\n",
    "        'f1_per_class': f1,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Eval loops\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    n = 0\n",
    "    for imgs, masks, _ in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        cm = confusion_matrix_from_logits(logits.detach(), masks.detach())\n",
    "        running_cm += cm\n",
    "        n += imgs.size(0)\n",
    "    avg_loss = running_loss / n\n",
    "    metrics = compute_metrics_from_cm(running_cm)\n",
    "    return avg_loss, metrics['mean_iou']\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, _ in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            running_cm += cm\n",
    "            n += imgs.size(0)\n",
    "    avg_loss = running_loss / n\n",
    "    metrics = compute_metrics_from_cm(running_cm)\n",
    "    return avg_loss, metrics['mean_iou']\n",
    "\n",
    "# -----------------------------\n",
    "# Full evaluation utilities\n",
    "# -----------------------------\n",
    "\n",
    "def evaluate_model_on_test(model, testset, criterion, device):\n",
    "    # As requested, use batch_size = len(testset)\n",
    "    testloader = DataLoader(testset, batch_size=len(testset))\n",
    "    return eval_one_epoch(model, testloader, criterion, device)\n",
    "\n",
    "\n",
    "def detailed_test_evaluation(model, testset, criterion, device, viz_dir=None, per_image_csv=None):\n",
    "    # Evaluate overall metrics and per-image metrics + save visualizations\n",
    "    model.eval()\n",
    "    all_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    per_image_rows = []\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, names in testloader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks).item()\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            all_cm += cm\n",
    "            m = compute_metrics_from_cm(cm)\n",
    "            pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            gt = masks.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            # Save visualization\n",
    "            if viz_dir is not None:\n",
    "                save_visualization(imgs.squeeze(0).cpu(), gt, pred, names[0], viz_dir)\n",
    "            row = {\n",
    "                'image': names[0],\n",
    "                'loss': loss,\n",
    "                'mIoU': m['mean_iou'],\n",
    "                'pixel_acc': m['pixel_acc'],\n",
    "                'mean_acc': m['mean_acc'],\n",
    "                'precision_class0': m['precision_per_class'][0],\n",
    "                'precision_class1': m['precision_per_class'][1],\n",
    "                'recall_class0': m['recall_per_class'][0],\n",
    "                'recall_class1': m['recall_per_class'][1],\n",
    "                'f1_class0': m['f1_per_class'][0],\n",
    "                'f1_class1': m['f1_per_class'][1],\n",
    "            }\n",
    "            per_image_rows.append(row)\n",
    "    overall = compute_metrics_from_cm(all_cm)\n",
    "    if per_image_csv is not None:\n",
    "        df = pd.DataFrame(per_image_rows)\n",
    "        df.to_csv(per_image_csv, index=False)\n",
    "    return overall, per_image_rows\n",
    "\n",
    "\n",
    "def save_visualization(img_tensor, gt_mask, pred_mask, name, viz_dir):\n",
    "    # img_tensor: normalized tensor; convert back to RGB\n",
    "    img = img_tensor.clone()\n",
    "    img = img * torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "    img = img + torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "    img = img.clamp(0,1).permute(1,2,0).numpy()\n",
    "    gt = gt_mask\n",
    "    pred = pred_mask\n",
    "    # Stack horizontally\n",
    "    fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Input')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(gt, cmap='gray')\n",
    "    axes[1].set_title('GT')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(pred, cmap='gray')\n",
    "    axes[2].set_title('Pred')\n",
    "    axes[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    outpath = os.path.join(viz_dir, f\"{os.path.splitext(name)[0]}_viz.png\")\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "# -----------------------------\n",
    "# Plot helpers\n",
    "# -----------------------------\n",
    "\n",
    "def plot_loss(history_csv, outpath):\n",
    "    df = pd.read_csv(history_csv)\n",
    "    plt.figure()\n",
    "    plt.plot(df['epoch'], df['train_loss'], label='train_loss')\n",
    "    plt.plot(df['epoch'], df['val_loss'], label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_acc(history_csv, outpath):\n",
    "    df = pd.read_csv(history_csv)\n",
    "    plt.figure()\n",
    "    plt.plot(df['epoch'], df['train_mIoU'], label='train_mIoU')\n",
    "    plt.plot(df['epoch'], df['val_mIoU'], label='val_mIoU')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mIoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def main(args):\n",
    "    start_time = time.time()\n",
    "    # Prepare datasets\n",
    "    train_imgs, train_masks = pair_images_and_masks(args.train_img_dir, args.train_mask_dir)\n",
    "    test_imgs, test_masks = pair_images_and_masks(args.test_img_dir, args.test_mask_dir)\n",
    "    assert len(train_imgs) > 0, 'No training images found'\n",
    "    assert len(test_imgs) > 0, 'No test images found'\n",
    "\n",
    "    # Split train/val if val dirs not provided\n",
    "    if args.val_img_dir is None or args.val_mask_dir is None:\n",
    "        n = len(train_imgs)\n",
    "        nval = max(1, int(n * args.valsplit))\n",
    "        # simple split\n",
    "        val_imgs = train_imgs[:nval]\n",
    "        val_masks = train_masks[:nval]\n",
    "        train_imgs2 = train_imgs[nval:]\n",
    "        train_masks2 = train_masks[nval:]\n",
    "    else:\n",
    "        val_imgs, val_masks = pair_images_and_masks(args.val_img_dir, args.val_mask_dir)\n",
    "        train_imgs2, train_masks2 = train_imgs, train_masks\n",
    "\n",
    "    trainset = MyDataset(train_imgs2, train_masks2, img_size=args.img_size)\n",
    "    valset = MyDataset(val_imgs, val_masks, img_size=args.img_size)\n",
    "    testset = MyDataset(test_imgs, test_masks, img_size=args.img_size)\n",
    "\n",
    "    # Dataloaders\n",
    "    trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "    valloader = DataLoader(valset, batch_size=min(len(valset), args.batch_size), shuffle=False, num_workers=2)\n",
    "\n",
    "    # Class weights\n",
    "    class_weights, counts, freq = compute_class_weights(trainset)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "    print(f\"Class counts: {counts}, freq: {freq}, weights: {class_weights}\")\n",
    "\n",
    "    # Prepare model\n",
    "    model = smp.DeepLabV3Plus(encoder_name='resnet50', encoder_weights='imagenet', in_channels=3, classes=2)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Loss selection\n",
    "    if args.loss_type == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    elif args.loss_type == 'dice':\n",
    "        criterion = DiceLoss()\n",
    "    elif args.loss_type == 'focal':\n",
    "        alpha = args.alpha_focal if args.alpha_focal is not None else class_weights.cpu().numpy().tolist()\n",
    "        criterion = FocalLoss(gamma=args.gamma_focal, alpha=alpha)\n",
    "    else:\n",
    "        raise ValueError('Unknown loss type')\n",
    "\n",
    "    # Optimizer\n",
    "    if args.optimizer_type.lower() == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "\n",
    "    # History store\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, args.num_epochs + 1):\n",
    "        train_loss, train_miou = train_one_epoch(model, trainloader, optimizer, criterion, DEVICE)\n",
    "        val_loss, val_miou = eval_one_epoch(model, valloader, criterion, DEVICE)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, train_mIoU={train_miou:.4f}, val_loss={val_loss:.4f}, val_mIoU={val_miou:.4f}\")\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'train_mIoU': train_miou, 'val_loss': val_loss, 'val_mIoU': val_miou})\n",
    "\n",
    "        # Save every epoch (to support per-epoch test evaluation). Also make note for 10-epoch saves.\n",
    "        model_path = os.path.join(args.model_dir, f\"{args.filedate}_epoch{epoch:03d}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        if epoch % 10 == 0:\n",
    "            periodic_path = os.path.join(args.model_dir, f\"{args.filedate}_epoch{epoch:03d}_periodic.pth\")\n",
    "            torch.save(model.state_dict(), periodic_path)\n",
    "\n",
    "        # Save history to CSV each epoch\n",
    "        df = pd.DataFrame(history)\n",
    "        df.to_csv(args.history_csv, index=False)\n",
    "\n",
    "    # After training: evaluate all saved epoch models on test set\n",
    "    print('Evaluating saved epoch models on test set...')\n",
    "    model_files = sorted(glob.glob(os.path.join(args.model_dir, f\"{args.filedate}_epoch*.pth\")))\n",
    "    per_epoch_results = []\n",
    "    for p in model_files:\n",
    "        state = torch.load(p, map_location=DEVICE)\n",
    "        model.load_state_dict(state)\n",
    "        test_loss, test_miou = evaluate_model_on_test(model, testset, criterion, DEVICE)\n",
    "        per_epoch_results.append({'model_file': os.path.basename(p), 'test_loss': test_loss, 'test_mIoU': test_miou})\n",
    "        print(f\"Model {os.path.basename(p)} -> test_loss={test_loss:.4f}, test_mIoU={test_miou:.4f}\")\n",
    "\n",
    "    per_epoch_df = pd.DataFrame(per_epoch_results)\n",
    "    per_epoch_csv = os.path.join(args.out_dir, f\"per_epoch_test_results_{args.filedate}.csv\")\n",
    "    per_epoch_df.to_csv(per_epoch_csv, index=False)\n",
    "\n",
    "    # Select best model by test mIoU\n",
    "    best_row = per_epoch_df.loc[per_epoch_df['test_mIoU'].idxmax()]\n",
    "    best_model_file = os.path.join(args.model_dir, best_row['model_file'])\n",
    "    print(f\"Best model: {best_model_file} with test_mIoU={best_row['test_mIoU']:.4f}\")\n",
    "    state = torch.load(best_model_file, map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    # Detailed evaluation with best model\n",
    "    per_image_csv = os.path.join(args.out_dir, f\"per_image_metrics_{args.filedate}.csv\")\n",
    "    overall_metrics, per_image_rows = detailed_test_evaluation(model, testset, criterion, DEVICE, viz_dir=args.viz_dir, per_image_csv=per_image_csv)\n",
    "\n",
    "    # Save overall metrics\n",
    "    overall_csv = os.path.join(args.out_dir, f\"overall_test_metrics_{args.filedate}.csv\")\n",
    "    with open(overall_csv, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['metric', 'value'])\n",
    "        writer.writerow(['loss', 'n/a'])\n",
    "        writer.writerow(['mIoU', overall_metrics['mean_iou']])\n",
    "        writer.writerow(['pixel_acc', overall_metrics['pixel_acc']])\n",
    "        writer.writerow(['mean_acc', overall_metrics['mean_acc']])\n",
    "        for i, p in enumerate(overall_metrics['precision_per_class']):\n",
    "            writer.writerow([f'precision_class{i}', p])\n",
    "        for i, r in enumerate(overall_metrics['recall_per_class']):\n",
    "            writer.writerow([f'recall_class{i}', r])\n",
    "        for i, f1 in enumerate(overall_metrics['f1_per_class']):\n",
    "            writer.writerow([f'f1_class{i}', f1])\n",
    "\n",
    "    # Plots\n",
    "    plot_loss(args.history_csv, os.path.join(args.plots_dir, f\"loss_{args.filedate}.png\"))\n",
    "    plot_acc(args.history_csv, os.path.join(args.plots_dir, f\"acc_{args.filedate}.png\"))\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    with open(args.runinfo_txt, 'w') as f:\n",
    "        f.write(f\"Start: {start_time}\\n\")\n",
    "        f.write(f\"End: {time.time()}\\n\")\n",
    "        f.write(f\"Elapsed seconds: {elapsed}\\n\")\n",
    "\n",
    "    print('Done. Outputs:')\n",
    "    print(f\" - models: {args.model_dir}\")\n",
    "    print(f\" - per-epoch test CSV: {per_epoch_csv}\")\n",
    "    print(f\" - best model: {best_model_file}\")\n",
    "    print(f\" - per-image CSV: {per_image_csv}\")\n",
    "    print(f\" - visualizations: {args.viz_dir}\")\n",
    "    print(f\" - history CSV: {args.history_csv}\")\n",
    "    print(f\" - plots: {args.plots_dir}\")\n",
    "    print(f\" - run info: {args.runinfo_txt}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--img_size', type=lambda s: tuple(map(int, s.split(','))), default=IMG_SIZE)\n",
    "    parser.add_argument('--batch_size', type=int, default=batch_size)\n",
    "    parser.add_argument('--num_epochs', type=int, default=num_epochs)\n",
    "    parser.add_argument('--valsplit', type=float, default=valsplit)\n",
    "    parser.add_argument('--learning_rate', type=float, default=learning_rate)\n",
    "    parser.add_argument('--loss_type', type=str, default=loss_type)\n",
    "    parser.add_argument('--optimizer_type', type=str, default=optimizer_type)\n",
    "    parser.add_argument('--train_img_dir', type=str, default=train_img_dir)\n",
    "    parser.add_argument('--train_mask_dir', type=str, default=train_mask_dir)\n",
    "    parser.add_argument('--val_img_dir', type=str, default=val_img_dir)\n",
    "    parser.add_argument('--val_mask_dir', type=str, default=val_mask_dir)\n",
    "    parser.add_argument('--test_img_dir', type=str, default=test_img_dir)\n",
    "    parser.add_argument('--test_mask_dir', type=str, default=test_mask_dir)\n",
    "    parser.add_argument('--model_dir', type=str, default=model_dir)\n",
    "    parser.add_argument('--out_dir', type=str, default=out_dir)\n",
    "    parser.add_argument('--viz_dir', type=str, default=viz_dir)\n",
    "    parser.add_argument('--history_csv', type=str, default=history_csv)\n",
    "    parser.add_argument('--plots_dir', type=str, default=plots_dir)\n",
    "    parser.add_argument('--runinfo_txt', type=str, default=runinfo_txt)\n",
    "    parser.add_argument('--filedate', type=str, default=filedate)\n",
    "    parser.add_argument('--gamma_focal', type=float, default=gamma_focal)\n",
    "    parser.add_argument('--alpha_focal', type=lambda s: list(map(float, s.split(','))) if s else None, default=alpha_focal)\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
