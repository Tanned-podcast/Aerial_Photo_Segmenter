{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7901c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library import successful.\n",
      "Class counts: [1037282  535582], freq: [0.65948613 0.34051387], weights: tensor([0.7582, 1.4684], device='cuda:0')\n",
      "Epoch 1: train_loss=0.6408, train_mIoU=0.4369, val_loss=0.3185, val_mIoU=0.7182\n",
      "Epoch 2: train_loss=0.4422, train_mIoU=0.8193, val_loss=0.2142, val_mIoU=0.8185\n",
      "Epoch 3: train_loss=0.3410, train_mIoU=0.8932, val_loss=0.1544, val_mIoU=0.8606\n",
      "Epoch 4: train_loss=0.2495, train_mIoU=0.9248, val_loss=0.1183, val_mIoU=0.8817\n",
      "Epoch 5: train_loss=0.2257, train_mIoU=0.9260, val_loss=0.1041, val_mIoU=0.8772\n",
      "Epoch 6: train_loss=0.1609, train_mIoU=0.9493, val_loss=0.1006, val_mIoU=0.8910\n",
      "Epoch 7: train_loss=0.1339, train_mIoU=0.9574, val_loss=0.0999, val_mIoU=0.8995\n",
      "Epoch 8: train_loss=0.1389, train_mIoU=0.9542, val_loss=0.1048, val_mIoU=0.8958\n",
      "Epoch 9: train_loss=0.1288, train_mIoU=0.9537, val_loss=0.1076, val_mIoU=0.8846\n",
      "Epoch 10: train_loss=0.1020, train_mIoU=0.9690, val_loss=0.1037, val_mIoU=0.8917\n",
      "Epoch 11: train_loss=0.1060, train_mIoU=0.9657, val_loss=0.0995, val_mIoU=0.8994\n",
      "Epoch 12: train_loss=0.0969, train_mIoU=0.9699, val_loss=0.1007, val_mIoU=0.8982\n",
      "Epoch 13: train_loss=0.0891, train_mIoU=0.9651, val_loss=0.0935, val_mIoU=0.8997\n",
      "Epoch 14: train_loss=0.0836, train_mIoU=0.9692, val_loss=0.0895, val_mIoU=0.9001\n",
      "Epoch 15: train_loss=0.0751, train_mIoU=0.9736, val_loss=0.0868, val_mIoU=0.9024\n",
      "Epoch 16: train_loss=0.0762, train_mIoU=0.9773, val_loss=0.0831, val_mIoU=0.9069\n",
      "Epoch 17: train_loss=0.0689, train_mIoU=0.9790, val_loss=0.0836, val_mIoU=0.9100\n",
      "Epoch 18: train_loss=0.0640, train_mIoU=0.9778, val_loss=0.0853, val_mIoU=0.9086\n",
      "Epoch 19: train_loss=0.0692, train_mIoU=0.9780, val_loss=0.0865, val_mIoU=0.9059\n",
      "Epoch 20: train_loss=0.0709, train_mIoU=0.9760, val_loss=0.0892, val_mIoU=0.9021\n",
      "Epoch 21: train_loss=0.0596, train_mIoU=0.9769, val_loss=0.0887, val_mIoU=0.9050\n",
      "Epoch 22: train_loss=0.0624, train_mIoU=0.9802, val_loss=0.0907, val_mIoU=0.9064\n",
      "Epoch 23: train_loss=0.0672, train_mIoU=0.9813, val_loss=0.0918, val_mIoU=0.9053\n",
      "Epoch 24: train_loss=0.0595, train_mIoU=0.9821, val_loss=0.0947, val_mIoU=0.9038\n",
      "Epoch 25: train_loss=0.0619, train_mIoU=0.9813, val_loss=0.0913, val_mIoU=0.9065\n",
      "Epoch 26: train_loss=0.0537, train_mIoU=0.9802, val_loss=0.0925, val_mIoU=0.9052\n",
      "Epoch 27: train_loss=0.0621, train_mIoU=0.9788, val_loss=0.0892, val_mIoU=0.9067\n",
      "Epoch 28: train_loss=0.0519, train_mIoU=0.9825, val_loss=0.0872, val_mIoU=0.9091\n",
      "Epoch 29: train_loss=0.0594, train_mIoU=0.9820, val_loss=0.0878, val_mIoU=0.9064\n",
      "Epoch 30: train_loss=0.0567, train_mIoU=0.9797, val_loss=0.0880, val_mIoU=0.9057\n",
      "Evaluating saved epoch models on test set...\n",
      "Model 20260103_1648_epoch010.pth -> test_loss=0.1304, test_mIoU=0.8906\n",
      "Model 20260103_1648_epoch020.pth -> test_loss=0.1214, test_mIoU=0.9085\n",
      "Model 20260103_1648_epoch030.pth -> test_loss=0.1116, test_mIoU=0.9163\n",
      "Best model: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Weights\\\\20260103_1648\\20260103_1648_epoch030.pth with test_mIoU=0.9163\n",
      "-----TRAINING AND EVALUATION ALL DONE!!!-----\n",
      "Outputs:\n",
      " - models: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Weights\\\\20260103_1648\n",
      " - per-epoch test CSV: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Result_Segmentation\\\\20260103_1648\\per_10epoch_test_results_20260103_1648.csv\n",
      " - best model: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Weights\\\\20260103_1648\\20260103_1648_epoch030.pth\n",
      " - per-image CSV: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Result_Segmentation\\\\20260103_1648\\Bestmodel_epoch030_per_image_metrics_20260103_1648.csv\n",
      " - visualizations: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Result_Segmentation\\\\20260103_1648\\Visualizations\n",
      " - history CSV: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\History\\\\20260103_1648\\history_20260103_1648.csv\n",
      " - plots: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\Result_Segmentation\\\\20260103_1648\\plots\n",
      " - run info: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\Sandbox\\SegCode_Test\\History\\\\20260103_1648\\runinfo_20260103_1648.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unified DeepLabV3+ training / validation / testing pipeline\n",
    "Supports: CE (with class weights), Dice, Focal losses\n",
    "- Computes class weights from train masks\n",
    "- Saves per-epoch model files (filename contains filedate_epochXX.pth)\n",
    "- Evaluates all saved epoch models on test set and selects best by test mIoU\n",
    "- Computes detailed metrics for best model and per-image CSV\n",
    "- Generates side-by-side visualizations for each test image\n",
    "- Saves training history (CSV) and plots\n",
    "- Records run time to TXT\n",
    "\n",
    "Requirements:\n",
    "- torch\n",
    "- torchvision (ensure it includes deeplabv3_resnet101)\n",
    "- PIL, numpy, pandas, matplotlib\n",
    "\n",
    "Place your images and masks in folders and set `train_img_dir`, `train_mask_dir`, etc., below or pass via command-line \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "\n",
    "print(\"Library import successful.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration (default)\n",
    "# -----------------------------\n",
    "IMG_SIZE = (64, 64)  # (H, W)\n",
    "Channels = 3\n",
    "batch_size = 2\n",
    "classes = ['background', 'debris']\n",
    "num_classes = len(classes)\n",
    "num_epochs = 30 #10以上にしないと重みセーブできなくてエラーになる\n",
    "valsplit = 0.25\n",
    "learning_rate = 1e-4\n",
    "loss_type = \"ce\"  # \"ce\" / \"dice\" / \"focal\"\n",
    "optimizer_type = \"adam\"  # adam / sgd\n",
    "gamma_focal = 2.0\n",
    "alpha_focal = None  # list or None, set after class weights computed\n",
    "\n",
    "# Data paths (set to your dataset)\n",
    "root_dir = r\"C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\"\n",
    "\n",
    "# Input dirs: the img and its mask has to have THE SAME FILENAME (different extensions allowed), or else they won't be paired.\n",
    "train_img_dir = Path(root_dir + r\"\\TrainVal\\img\")\n",
    "train_mask_dir = root_dir + r\"\\TrainVal\\mask\"\n",
    "\n",
    "val_img_dir = None  # if None, split from train\n",
    "val_mask_dir = None\n",
    "test_img_dir = root_dir + r\"\\Test\\img\"\n",
    "test_mask_dir = root_dir + r\"\\Test\\mask\"\n",
    "\n",
    "# Output dirs (will include filedate)\n",
    "history_root = root_dir + r\"\\History\\\\\"\n",
    "model_root = root_dir + r\"\\Weights\\\\\"\n",
    "result_root = root_dir + r\"\\Result_Segmentation\\\\\"\n",
    "os.makedirs(history_root, exist_ok=True)\n",
    "os.makedirs(result_root, exist_ok=True)\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "\n",
    "filedate = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "history_dir = history_root + filedate\n",
    "model_dir = model_root + filedate\n",
    "result_dir = result_root + filedate\n",
    "viz_dir = result_dir + r\"\\Visualizations\"\n",
    "pred_dir = result_dir + r\"\\PredMasks\"\n",
    "\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "history_csv = os.path.join(history_dir, f\"history_{filedate}.csv\")\n",
    "runinfo_txt = os.path.join(history_dir, f\"runinfo_{filedate}.txt\")\n",
    "plots_dir = os.path.join(result_dir, \"plots\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"IMG_SIZE: {IMG_SIZE}, batch_size: {batch_size}, classes: {classes}, num_classes: {num_classes}\",\n",
    "      f\"\\nnum_epochs: {num_epochs}, valsplit: {valsplit}, learning_rate: {learning_rate}\",\n",
    "      f\"\\nloss_type: {loss_type}, optimizer_type: {optimizer_type}, DEVICE: {DEVICE}\",\n",
    "      \"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, img_size=IMG_SIZE, transforms=None):\n",
    "        assert len(img_paths) == len(mask_paths)\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.img_size = img_size\n",
    "        # transforms for image (tensor & normalize)\n",
    "        self.transforms = transforms or T.Compose([\n",
    "            T.Resize(img_size, interpolation=Image.BILINEAR),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # mask transforms (nearest, preserve labels)\n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize(img_size, interpolation=Image.NEAREST),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "        img = self.transforms(img)\n",
    "        mask = self.mask_transform(mask)\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        # Convert {0,255} -> {0,1}\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return img, mask, os.path.basename(self.img_paths[idx])\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities: file pairing\n",
    "# -----------------------------\n",
    "\n",
    "def pair_images_and_masks(img_dir, mask_dir, img_exts=['.jpg', '.png', '.tif', '.tiff'], mask_exts=['.png']):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    for ext in img_exts:\n",
    "        imgs.extend(glob.glob(os.path.join(img_dir, f\"*{ext}\")))\n",
    "    imgs = sorted(imgs)\n",
    "    mask_map = {}\n",
    "    for ext in mask_exts:\n",
    "        for p in glob.glob(os.path.join(mask_dir, f\"*{ext}\")):\n",
    "            mask_map[os.path.splitext(os.path.basename(p))[0]] = p\n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    for p in imgs:\n",
    "        stem = os.path.splitext(os.path.basename(p))[0]\n",
    "        if stem in mask_map:\n",
    "            img_paths.append(p)\n",
    "            mask_paths.append(mask_map[stem])\n",
    "    return img_paths, mask_paths\n",
    "\n",
    "# For the Test Dataset: record original sizes\n",
    "def pair_test_images_and_masks(img_dir, mask_dir, img_exts=['.jpg', '.png', '.tif', '.tiff'], mask_exts=['.png']):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    for ext in img_exts:\n",
    "        imgs.extend(glob.glob(os.path.join(img_dir, f\"*{ext}\")))\n",
    "    imgs = sorted(imgs)\n",
    "    mask_map = {}\n",
    "    for ext in mask_exts:\n",
    "        for p in glob.glob(os.path.join(mask_dir, f\"*{ext}\")):\n",
    "            mask_map[os.path.splitext(os.path.basename(p))[0]] = p\n",
    "            \n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    test_orig_sizes = {}\n",
    "    for p in imgs:\n",
    "        stem = os.path.splitext(os.path.basename(p))[0]\n",
    "        if stem in mask_map:\n",
    "            img_paths.append(p)\n",
    "            mask_paths.append(mask_map[stem])\n",
    "            try:\n",
    "                with Image.open(p) as im:\n",
    "                    w, h = im.size\n",
    "                test_orig_sizes[stem] = (h, w)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return img_paths, mask_paths, test_orig_sizes\n",
    "\n",
    "# -----------------------------\n",
    "# Class weight computation\n",
    "# -----------------------------\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    for i in range(len(dataset)):\n",
    "        _, mask, _ = dataset[i]\n",
    "        mask_np = mask.numpy().ravel()\n",
    "        for c in range(num_classes):\n",
    "            counts[c] += int((mask_np == c).sum())\n",
    "    total = counts.sum()\n",
    "    freq = counts / total\n",
    "    # weight: inverse of frequency\n",
    "    weights = total / (num_classes * counts)\n",
    "    weights = weights.astype(np.float32)\n",
    "    return weights, counts, freq\n",
    "\n",
    "# -----------------------------\n",
    "# Losses\n",
    "# -----------------------------\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B,C,H,W], target: [B,H,W]\n",
    "        # num_classes = logits.shape[1]\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        target_onehot = nn.functional.one_hot(target, num_classes).permute(0,3,1,2).float()\n",
    "        dims = (0,2,3)\n",
    "        intersection = torch.sum(probs * target_onehot, dims)\n",
    "        cardinality = torch.sum(probs + target_onehot, dims)\n",
    "        dice_score = (2. * intersection + self.eps) / (cardinality + self.eps)\n",
    "        loss = 1. - dice_score.mean()\n",
    "        return loss\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        if alpha is not None:\n",
    "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B,C,H,W], target: [B,H,W]\n",
    "        ce = nn.functional.cross_entropy(logits, target, reduction='none')\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pt = probs.gather(1, target.unsqueeze(1)).squeeze(1)  # [B,H,W]\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "        loss = focal_term * ce\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(logits.device)\n",
    "            at = alpha.gather(0, target.flatten()).view_as(target).to(logits.device)\n",
    "            loss = at * loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "\n",
    "def confusion_matrix_from_logits(logits, target):\n",
    "    # logits: [B,C,H,W] or [B,1,H,W]\n",
    "    preds = torch.argmax(logits, dim=1).view(-1).cpu().numpy()\n",
    "    t = target.view(-1).cpu().numpy()\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for gt, pd in zip(t, preds):\n",
    "        cm[gt, pd] += 1\n",
    "    return cm\n",
    "\n",
    "\n",
    "def compute_metrics_from_cm(cm):\n",
    "    # cm: [num_classes,num_classes] where rows=gt, cols=pred\n",
    "    num_classes = cm.shape[0]\n",
    "    eps = 1e-6\n",
    "    tp = np.diag(cm).astype(float)\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    tn = cm.sum() - (tp + fp + fn)\n",
    "    # per-class IoU\n",
    "    iou = tp / (tp + fp + fn + eps)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    pixel_acc = tp.sum() / (cm.sum() + eps)\n",
    "    # per-class accuracy: tp / (tp + fn)\n",
    "    class_acc = tp / (tp + fn + eps)\n",
    "    mean_acc = np.nanmean(class_acc)\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "    return {\n",
    "        'iou_per_class': iou,\n",
    "        'mean_iou': mean_iou,\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_acc': mean_acc,\n",
    "        'precision_per_class': precision,\n",
    "        'recall_per_class': recall,\n",
    "        'f1_per_class': f1,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Eval loops\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    n = 0\n",
    "    for imgs, masks, _ in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        cm = confusion_matrix_from_logits(logits.detach(), masks.detach())\n",
    "        running_cm += cm\n",
    "        n += imgs.size(0)\n",
    "    avg_loss = running_loss / n\n",
    "    metrics = compute_metrics_from_cm(running_cm)\n",
    "    return avg_loss, metrics['mean_iou']\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, _ in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            running_cm += cm\n",
    "            n += imgs.size(0)\n",
    "    avg_loss = running_loss / n\n",
    "    metrics = compute_metrics_from_cm(running_cm)\n",
    "    return avg_loss, metrics['mean_iou']\n",
    "\n",
    "# -----------------------------\n",
    "# Full evaluation utilities\n",
    "# -----------------------------\n",
    "\n",
    "def evaluate_model_on_test(model, testset, criterion, device):\n",
    "    # As requested, use batch_size = len(testset)\n",
    "    testloader = DataLoader(testset, batch_size=len(testset))\n",
    "    return eval_one_epoch(model, testloader, criterion, device)\n",
    "\n",
    "\n",
    "def detailed_test_evaluation(model, testset, criterion, device, viz_dir=None, per_image_csv=None, overall_image_csv=None, test_orig_sizes=None):\n",
    "    \"\"\"Evaluate overall metrics and per-image metrics + save visualizations.\n",
    "\n",
    "    Adds per-image TP/FP/TN/FN/Total pixel counts (binary positive=class 1),\n",
    "    and per-class IoU values to the per-image CSV.\n",
    "    Also appends aggregate binary counts to the returned overall metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    per_image_rows = []\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, names in testloader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks).item()\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            all_cm += cm\n",
    "            m = compute_metrics_from_cm(cm)\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            gt = masks.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            # Save visualization (if requested)\n",
    "            if viz_dir is not None:\n",
    "                save_visualization(imgs.squeeze(0).cpu(), gt, pred, names[0], viz_dir, pred_dir, test_orig_sizes=test_orig_sizes)\n",
    "\n",
    "            # Binary confusion counts for class 1 (debris) vs class 0 (background)\n",
    "            # For 2-class case: TP = cm[1,1], FP = cm[0,1], FN = cm[1,0], TN = cm[0,0]\n",
    "            total_pixels = int(cm.sum())\n",
    "\n",
    "            # per-class IoU\n",
    "            iou_c = m['iou_per_class']\n",
    "            iou_c0 = float(iou_c[0])\n",
    "            iou_c1 = float(iou_c[1])\n",
    "\n",
    "            row = {\n",
    "                'image': names[0],\n",
    "                'loss': loss,\n",
    "                'mIoU': m['mean_iou'],\n",
    "                'pixel_acc': m['pixel_acc'],\n",
    "                'mean_acc': m['mean_acc'],\n",
    "                'iou_class0': iou_c0,\n",
    "                'iou_class1': iou_c1,\n",
    "                'precision_class0': m['precision_per_class'][0],\n",
    "                'precision_class1': m['precision_per_class'][1],\n",
    "                'recall_class0': m['recall_per_class'][0],\n",
    "                'recall_class1': m['recall_per_class'][1],\n",
    "                'f1_class0': m['f1_per_class'][0],\n",
    "                'f1_class1': m['f1_per_class'][1],\n",
    "                'TP': m['tp'],\n",
    "                'FP': m['fp'],\n",
    "                'TN': m['tn'],\n",
    "                'FN': m['fn'],\n",
    "                'Total': total_pixels,\n",
    "            }\n",
    "            per_image_rows.append(row)\n",
    "    \n",
    "    if per_image_csv is not None:\n",
    "        df = pd.DataFrame(per_image_rows)\n",
    "        df.to_csv(per_image_csv, index=False)\n",
    "\n",
    "    overall = compute_metrics_from_cm(all_cm)\n",
    "    # Add aggregate binary counts to the overall metrics for convenience\n",
    "\n",
    "    overall_row = {\n",
    "        'pixel_acc': overall['pixel_acc'],\n",
    "        'mean_acc': overall['mean_acc'],\n",
    "        'iou_class0': float(overall['iou_per_class'][0]),\n",
    "        'iou_class1': float(overall['iou_per_class'][1]),\n",
    "        'precision_class0': overall['precision_per_class'][0],\n",
    "        'precision_class1': overall['precision_per_class'][1],\n",
    "        'recall_class0': overall['recall_per_class'][0],\n",
    "        'recall_class1': overall['recall_per_class'][1],\n",
    "        'f1_class0': overall['f1_per_class'][0],\n",
    "        'f1_class1': overall['f1_per_class'][1],\n",
    "        'TP': overall['tp'],\n",
    "        'FP': overall['fp'],\n",
    "        'TN': overall['tn'],\n",
    "        'FN': overall['fn'],\n",
    "        'Total': int(all_cm.sum()),\n",
    "    }\n",
    "\n",
    "    if overall_image_csv is not None:\n",
    "        df = pd.DataFrame([overall_row])\n",
    "        df.to_csv(overall_image_csv, index=False)\n",
    "\n",
    "    return overall_row, per_image_rows\n",
    "\n",
    "\n",
    "def save_visualization(img_tensor, gt_mask, pred_mask, name, viz_dir, pred_dir, test_orig_sizes={}):\n",
    "    \"\"\"Save side-by-side visualization (Input | GT | Pred) and also save the predicted mask\n",
    "    as a separate grayscale PNG under viz_dir/pred_masks/ with filename <name>_pred_mask.png.\n",
    "    \"\"\"\n",
    "    # img_tensor: normalized tensor; convert back to RGB\n",
    "    img = img_tensor.clone()\n",
    "    img = img * torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "    img = img + torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "    img = img.clamp(0,1).permute(1,2,0).numpy()\n",
    "    gt = gt_mask\n",
    "    pred = pred_mask\n",
    "\n",
    "    # Stack horizontally\n",
    "    fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Input')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(gt, cmap='gray')\n",
    "    axes[1].set_title('GT')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(pred, cmap='gray')\n",
    "    axes[2].set_title('Pred')\n",
    "    axes[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Ensure visualization dir exists and save combined image\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    outpath = os.path.join(viz_dir, f\"{os.path.splitext(name)[0]}_viz.png\")\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Also save predicted mask as a grayscale PNG (0 or 255 values) in 'pred_masks' subdir\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "    # pred may be 0/1; convert to 0/255 uint8\n",
    "    pred_img = (pred.astype(np.uint8) * 255)\n",
    "    pred_pil = Image.fromarray(pred_img, mode='L')\n",
    "    # Determine orig size: precedence argument -> test_orig_sizes mapping\n",
    "    stem = os.path.splitext(name)[0]\n",
    "    if test_orig_sizes is not None:\n",
    "        orig = test_orig_sizes.get(stem, None)\n",
    "        # orig is (H, W)\n",
    "        orig_w = int(orig[1])\n",
    "        orig_h = int(orig[0])\n",
    "        pred_pil = pred_pil.resize((orig_w, orig_h), resample=Image.NEAREST)\n",
    "    pred_out = os.path.join(pred_dir, f\"{stem}_pred_mask.png\")\n",
    "    pred_pil.save(pred_out)\n",
    "\n",
    "# -----------------------------\n",
    "# Plot helpers\n",
    "# -----------------------------\n",
    "\n",
    "def plot_loss(history_csv, outpath):\n",
    "    df = pd.read_csv(history_csv)\n",
    "    plt.figure()\n",
    "    plt.plot(df['epoch'], df['train_loss'], label='train_loss')\n",
    "    plt.plot(df['epoch'], df['val_loss'], label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_acc(history_csv, outpath):\n",
    "    df = pd.read_csv(history_csv)\n",
    "    plt.figure()\n",
    "    plt.plot(df['epoch'], df['train_mIoU'], label='train_mIoU')\n",
    "    plt.plot(df['epoch'], df['val_mIoU'], label='val_mIoU')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mIoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.datetime.now().strftime('%Y%m%d_%H:%M:%S')\n",
    "    print(f\"Started at {start_time}\")\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_imgs, train_masks = pair_images_and_masks(train_img_dir, train_mask_dir)\n",
    "    test_imgs, test_masks, test_orig_sizes = pair_test_images_and_masks(test_img_dir, test_mask_dir)\n",
    "    assert len(train_imgs) > 0, 'No training images found'\n",
    "    assert len(test_imgs) > 0, 'No test images found'\n",
    "\n",
    "    # Split train/val if val dirs not provided\n",
    "    if val_img_dir is None or val_mask_dir is None:\n",
    "        n = len(train_imgs)\n",
    "        nval = max(1, int(n * valsplit))\n",
    "        # simple split\n",
    "        val_imgs = train_imgs[:nval]\n",
    "        val_masks = train_masks[:nval]\n",
    "        train_imgs2 = train_imgs[nval:]\n",
    "        train_masks2 = train_masks[nval:]\n",
    "    else:\n",
    "        val_imgs, val_masks = pair_images_and_masks(val_img_dir, val_mask_dir)\n",
    "        train_imgs2, train_masks2 = train_imgs, train_masks\n",
    "\n",
    "    trainset = MyDataset(train_imgs2, train_masks2, img_size=IMG_SIZE)\n",
    "    valset = MyDataset(val_imgs, val_masks, img_size=IMG_SIZE)\n",
    "    testset = MyDataset(test_imgs, test_masks, img_size=IMG_SIZE)\n",
    "\n",
    "    # Dataloaders\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    valloader = DataLoader(valset, batch_size=min(len(valset), batch_size), shuffle=False, num_workers=0)\n",
    "\n",
    "    size = len(trainloader.dataset)\n",
    "    num_batches = len(trainloader)\n",
    "    size_val = len(valloader.dataset)\n",
    "    num_batches_val = len(valloader)\n",
    "    size_test = len(testset)\n",
    "    print(f\"TrainData Size: {size}, TrainData Batches: {num_batches}\", \n",
    "          f\"\\nValData Size: {size_val}, ValData Batches: {num_batches_val}\"\n",
    "          f\"\\nTestData Size: {size_test}, TestData Batches: 1\")\n",
    "\n",
    "    # Class weights\n",
    "    class_weights, counts, freq = compute_class_weights(trainset)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "    print(f\"Class counts: {counts}, freq: {freq}, weights: {class_weights}\")\n",
    "\n",
    "    # Prepare model (use torchvision's deeplabv3_resnet101)\n",
    "    model = deeplabv3_resnet101(weights=DeepLabV3_ResNet101_Weights.DEFAULT)\n",
    "    # ヘッドを置き換え\n",
    "    model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "    model.aux_classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Loss selection\n",
    "    if loss_type == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    elif loss_type == 'dice':\n",
    "        criterion = DiceLoss()\n",
    "    elif loss_type == 'focal':\n",
    "        alpha = alpha_focal if alpha_focal is not None else class_weights.cpu().numpy().tolist()\n",
    "        criterion = FocalLoss(gamma=gamma_focal, alpha=alpha)\n",
    "    else:\n",
    "        raise ValueError('Unknown loss type')\n",
    "\n",
    "    # Optimizer\n",
    "    if optimizer_type.lower() == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    # History store\n",
    "    history = []\n",
    "\n",
    "    # Training loop\n",
    "    print(\"-----TRAINING PHASE-----\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_miou = train_one_epoch(model, trainloader, optimizer, criterion, DEVICE)\n",
    "        val_loss, val_miou = eval_one_epoch(model, valloader, criterion, DEVICE)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, train_mIoU={train_miou:.4f}, val_loss={val_loss:.4f}, val_mIoU={val_miou:.4f}\")\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'train_mIoU': train_miou, 'val_loss': val_loss, 'val_mIoU': val_miou})\n",
    "\n",
    "        # Save every 10 epoch (to support per10-epoch test evaluation).\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Saving Model...\")\n",
    "            model_path = os.path.join(model_dir, f\"{filedate}_epoch{epoch:03d}.pth\")\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"Model saved to\", model_path)\n",
    "\n",
    "        # Save history to CSV each epoch\n",
    "        df = pd.DataFrame(history)\n",
    "        df.to_csv(history_csv, index=False)\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    print(\"-----EVALUATION PHASE-----\")\n",
    "\n",
    "    # After training: evaluate all saved epoch models on test set\n",
    "    print('Evaluating saved epoch models on test set...')\n",
    "    model_files = sorted(glob.glob(os.path.join(model_dir, f\"{filedate}_epoch*.pth\")))\n",
    "    per_epoch_results = []\n",
    "    for p in model_files:\n",
    "        state = torch.load(p, map_location=DEVICE)\n",
    "        model.load_state_dict(state)\n",
    "        test_loss, test_miou = evaluate_model_on_test(model, testset, criterion, DEVICE)\n",
    "        per_epoch_results.append({'model_file': os.path.basename(p), 'test_loss': test_loss, 'test_mIoU': test_miou})\n",
    "        print(f\"Model {os.path.basename(p)} -> test_loss={test_loss:.4f}, test_mIoU={test_miou:.4f}\")\n",
    "\n",
    "    per_epoch_df = pd.DataFrame(per_epoch_results)\n",
    "    per_epoch_csv = os.path.join(result_dir, f\"per_10epoch_test_results_{filedate}.csv\")\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    per_epoch_df.to_csv(per_epoch_csv, index=False)\n",
    "\n",
    "    # Select best model by test mIoU\n",
    "    best_row = per_epoch_df.loc[per_epoch_df['test_mIoU'].idxmax()]\n",
    "    best_model_file = os.path.join(model_dir, best_row['model_file'])\n",
    "    print(f\"Best model: {best_model_file} with test_mIoU={best_row['test_mIoU']:.4f}\")\n",
    "    best_epoch = best_row['model_file'].split('_')[-1].split('.')[0]\n",
    "    state = torch.load(best_model_file, map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    # Detailed evaluation with best model\n",
    "    per_image_csv = os.path.join(result_dir, f\"Bestmodel_{best_epoch}_per_image_metrics_{filedate}.csv\")\n",
    "    overall_image_csv = os.path.join(result_dir, f\"Bestmodel_{best_epoch}_overall_image_metrics_{filedate}.csv\")\n",
    "    overall_metrics, per_image_rows = detailed_test_evaluation(\n",
    "        model, testset, criterion, DEVICE, viz_dir=viz_dir, per_image_csv=per_image_csv, overall_image_csv=overall_image_csv, test_orig_sizes=test_orig_sizes)\n",
    "\n",
    "    # Plots\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    plot_loss(history_csv, os.path.join(plots_dir, f\"loss_{filedate}.png\"))\n",
    "    plot_acc(history_csv, os.path.join(plots_dir, f\"acc_{filedate}.png\"))\n",
    "\n",
    "    end_time = datetime.datetime.now().strftime('%Y%m%d_%H:%M:%S')\n",
    "    print(f\"Ended at {end_time}\")\n",
    "\n",
    "    with open(runinfo_txt, 'w') as f:\n",
    "        f.write(f\"Start: {start_time}\\n\")\n",
    "        f.write(f\"End: {end_time}\\n\")\n",
    "\n",
    "    print('-----TRAINING AND EVALUATION ALL DONE!!!-----')\n",
    "    print('Outputs:')\n",
    "    print(f\" - models: {model_dir}\")\n",
    "    print(f\" - per-epoch test CSV: {per_epoch_csv}\")\n",
    "    print(f\" - best model: {best_model_file}\")\n",
    "    print(f\" - per-image CSV: {per_image_csv}\")\n",
    "    print(f\" - visualizations: {viz_dir}\")\n",
    "    print(f\" - history CSV: {history_csv}\")\n",
    "    print(f\" - plots: {plots_dir}\")\n",
    "    print(f\" - run info: {runinfo_txt}\")\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aerial_Photo_Segmenter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
