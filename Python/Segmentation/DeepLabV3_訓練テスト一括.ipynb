{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7901c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library import successful.\n",
      "Class counts: [21940  2636], freq: [0.89274089 0.10725911], weights: tensor([0.5601, 4.6616], device='cuda:0')\n",
      "Epoch 1: train_loss=0.6671, train_mIoU=0.3787, val_loss=0.7981, val_mIoU=0.3262\n",
      "Epoch 2: train_loss=0.6413, train_mIoU=0.3968, val_loss=0.7598, val_mIoU=0.3282\n",
      "Epoch 3: train_loss=0.6020, train_mIoU=0.4157, val_loss=0.7702, val_mIoU=0.3563\n",
      "Epoch 4: train_loss=0.5479, train_mIoU=0.4774, val_loss=0.8045, val_mIoU=0.3338\n",
      "Epoch 5: train_loss=0.5157, train_mIoU=0.4993, val_loss=0.7192, val_mIoU=0.3192\n",
      "Epoch 6: train_loss=0.4658, train_mIoU=0.4826, val_loss=0.8254, val_mIoU=0.2977\n",
      "Epoch 7: train_loss=0.4228, train_mIoU=0.5110, val_loss=0.9108, val_mIoU=0.2831\n",
      "Epoch 8: train_loss=0.3859, train_mIoU=0.5439, val_loss=0.9730, val_mIoU=0.2951\n",
      "Epoch 9: train_loss=0.3654, train_mIoU=0.5791, val_loss=0.9736, val_mIoU=0.2572\n",
      "Epoch 10: train_loss=0.3285, train_mIoU=0.5951, val_loss=0.9957, val_mIoU=0.3104\n",
      "Evaluating saved epoch models on test set...\n",
      "Model 20260103_1513_epoch010.pth -> test_loss=0.8712, test_mIoU=0.4862\n",
      "Best model: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Weights\\\\20260103_1513\\20260103_1513_epoch010.pth with test_mIoU=0.4862\n",
      "-----TRAINING AND EVALUATION ALL DONE!!!-----\n",
      "Outputs:\n",
      " - models: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Weights\\\\20260103_1513\n",
      " - per-epoch test CSV: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Result_Segmentation\\\\20260103_1513\\per_10epoch_test_results_20260103_1513.csv\n",
      " - best model: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Weights\\\\20260103_1513\\20260103_1513_epoch010.pth\n",
      " - per-image CSV: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Result_Segmentation\\\\20260103_1513\\Bestmodel_epoch010_per_image_metrics_20260103_1513.csv\n",
      " - visualizations: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Result_Segmentation\\\\20260103_1513\\Visualizations\n",
      " - history CSV: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\History\\\\20260103_1513\\history_20260103_1513.csv\n",
      " - plots: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\Result_Segmentation\\\\20260103_1513\\plots\n",
      " - run info: C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\\History\\\\20260103_1513\\runinfo_20260103_1513.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unified DeepLabV3+ training / validation / testing pipeline\n",
    "Supports: CE (with class weights), Dice, Focal losses\n",
    "- Computes class weights from train masks\n",
    "- Saves per-epoch model files (filename contains filedate_epochXX.pth)\n",
    "- Evaluates all saved epoch models on test set and selects best by test mIoU\n",
    "- Computes detailed metrics for best model and per-image CSV\n",
    "- Generates side-by-side visualizations for each test image\n",
    "- Saves training history (CSV) and plots\n",
    "- Records run time to TXT\n",
    "\n",
    "Requirements:\n",
    "- torch\n",
    "- torchvision (ensure it includes deeplabv3_resnet101)\n",
    "- PIL, numpy, pandas, matplotlib\n",
    "\n",
    "Place your images and masks in folders and set `train_img_dir`, `train_mask_dir`, etc., below or pass via command-line \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "import csv\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "\n",
    "print(\"Library import successful.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration (default)\n",
    "# -----------------------------\n",
    "IMG_SIZE = (64, 64)  # (H, W)\n",
    "Channels = 3\n",
    "batch_size = 2\n",
    "classes = ['background', 'debris']\n",
    "num_classes = len(classes)\n",
    "num_epochs = 10 #10以上にしないと重みセーブできなくてエラーになる\n",
    "valsplit = 0.25\n",
    "learning_rate = 1e-4\n",
    "loss_type = \"ce\"  # \"ce\" / \"dice\" / \"focal\"\n",
    "optimizer_type = \"adam\"  # adam / sgd\n",
    "gamma_focal = 2.0\n",
    "alpha_focal = None  # list or None, set after class weights computed\n",
    "\n",
    "# Data paths (set to your dataset)\n",
    "root_dir = r\"C:\\Users\\kyohe\\Aerial_Photo_Segmenter\\20251209Data\"\n",
    "\n",
    "# Input dirs: the img and its mask has to have THE SAME FILENAME (different extensions allowed), or else they won't be paired.\n",
    "train_img_dir = Path(root_dir + r\"\\TrainVal\\img\")\n",
    "train_mask_dir = root_dir + r\"\\TrainVal\\mask\"\n",
    "\n",
    "val_img_dir = None  # if None, split from train\n",
    "val_mask_dir = None\n",
    "test_img_dir = root_dir + r\"\\Test\\img\"\n",
    "test_mask_dir = root_dir + r\"\\Test\\mask\"\n",
    "\n",
    "# Output dirs (will include filedate)\n",
    "history_root = root_dir + r\"\\History\\\\\"\n",
    "model_root = root_dir + r\"\\Weights\\\\\"\n",
    "result_root = root_dir + r\"\\Result_Segmentation\\\\\"\n",
    "os.makedirs(history_root, exist_ok=True)\n",
    "os.makedirs(result_root, exist_ok=True)\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "\n",
    "filedate = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "history_dir = history_root + filedate\n",
    "model_dir = model_root + filedate\n",
    "result_dir = result_root + filedate\n",
    "viz_dir = result_dir + r\"\\Visualizations\"\n",
    "pred_dir = result_dir + r\"\\PredMasks\"\n",
    "\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "history_csv = os.path.join(history_dir, f\"history_{filedate}.csv\")\n",
    "runinfo_txt = os.path.join(history_dir, f\"runinfo_{filedate}.txt\")\n",
    "plots_dir = os.path.join(result_dir, \"plots\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, img_size=IMG_SIZE, transforms=None):\n",
    "        assert len(img_paths) == len(mask_paths)\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.img_size = img_size\n",
    "        # transforms for image (tensor & normalize)\n",
    "        self.transforms = transforms or T.Compose([\n",
    "            T.Resize(img_size, interpolation=Image.BILINEAR),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # mask transforms (nearest, preserve labels)\n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize(img_size, interpolation=Image.NEAREST),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "        img = self.transforms(img)\n",
    "        mask = self.mask_transform(mask)\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        # Convert {0,255} -> {0,1}\n",
    "        mask = (mask > 127).astype(np.uint8)\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return img, mask, os.path.basename(self.img_paths[idx])\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities: file pairing\n",
    "# -----------------------------\n",
    "\n",
    "def pair_images_and_masks(img_dir, mask_dir, img_exts=['.jpg', '.png', '.tif', '.tiff'], mask_exts=['.png']):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    for ext in img_exts:\n",
    "        imgs.extend(glob.glob(os.path.join(img_dir, f\"*{ext}\")))\n",
    "    imgs = sorted(imgs)\n",
    "    mask_map = {}\n",
    "    for ext in mask_exts:\n",
    "        for p in glob.glob(os.path.join(mask_dir, f\"*{ext}\")):\n",
    "            mask_map[os.path.splitext(os.path.basename(p))[0]] = p\n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    for p in imgs:\n",
    "        stem = os.path.splitext(os.path.basename(p))[0]\n",
    "        if stem in mask_map:\n",
    "            img_paths.append(p)\n",
    "            mask_paths.append(mask_map[stem])\n",
    "    return img_paths, mask_paths\n",
    "\n",
    "# For the Test Dataset: record original sizes\n",
    "def pair_test_images_and_masks(img_dir, mask_dir, img_exts=['.jpg', '.png', '.tif', '.tiff'], mask_exts=['.png']):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    for ext in img_exts:\n",
    "        imgs.extend(glob.glob(os.path.join(img_dir, f\"*{ext}\")))\n",
    "    imgs = sorted(imgs)\n",
    "    mask_map = {}\n",
    "    for ext in mask_exts:\n",
    "        for p in glob.glob(os.path.join(mask_dir, f\"*{ext}\")):\n",
    "            mask_map[os.path.splitext(os.path.basename(p))[0]] = p\n",
    "            \n",
    "    img_paths = []\n",
    "    mask_paths = []\n",
    "    test_orig_sizes = {}\n",
    "    for p in imgs:\n",
    "        stem = os.path.splitext(os.path.basename(p))[0]\n",
    "        if stem in mask_map:\n",
    "            img_paths.append(p)\n",
    "            mask_paths.append(mask_map[stem])\n",
    "            try:\n",
    "                with Image.open(p) as im:\n",
    "                    w, h = im.size\n",
    "                test_orig_sizes[stem] = (h, w)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return img_paths, mask_paths, test_orig_sizes\n",
    "\n",
    "# -----------------------------\n",
    "# Class weight computation\n",
    "# -----------------------------\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    for i in range(len(dataset)):\n",
    "        _, mask, _ = dataset[i]\n",
    "        mask_np = mask.numpy().ravel()\n",
    "        for c in range(num_classes):\n",
    "            counts[c] += int((mask_np == c).sum())\n",
    "    total = counts.sum()\n",
    "    freq = counts / total\n",
    "    # weight: inverse of frequency\n",
    "    weights = total / (num_classes * counts)\n",
    "    weights = weights.astype(np.float32)\n",
    "    return weights, counts, freq\n",
    "\n",
    "# -----------------------------\n",
    "# Losses\n",
    "# -----------------------------\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B,C,H,W], target: [B,H,W]\n",
    "        # num_classes = logits.shape[1]\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        target_onehot = nn.functional.one_hot(target, num_classes).permute(0,3,1,2).float()\n",
    "        dims = (0,2,3)\n",
    "        intersection = torch.sum(probs * target_onehot, dims)\n",
    "        cardinality = torch.sum(probs + target_onehot, dims)\n",
    "        dice_score = (2. * intersection + self.eps) / (cardinality + self.eps)\n",
    "        loss = 1. - dice_score.mean()\n",
    "        return loss\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        if alpha is not None:\n",
    "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B,C,H,W], target: [B,H,W]\n",
    "        ce = nn.functional.cross_entropy(logits, target, reduction='none')\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pt = probs.gather(1, target.unsqueeze(1)).squeeze(1)  # [B,H,W]\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "        loss = focal_term * ce\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(logits.device)\n",
    "            at = alpha.gather(0, target.flatten()).view_as(target).to(logits.device)\n",
    "            loss = at * loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "\n",
    "def confusion_matrix_from_logits(logits, target):\n",
    "    # logits: [B,C,H,W] or [B,1,H,W]\n",
    "    preds = torch.argmax(logits, dim=1).view(-1).cpu().numpy()\n",
    "    t = target.view(-1).cpu().numpy()\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for gt, pd in zip(t, preds):\n",
    "        cm[gt, pd] += 1\n",
    "    return cm\n",
    "\n",
    "\n",
    "def compute_metrics_from_cm(cm):\n",
    "    # cm: [num_classes,num_classes] where rows=gt, cols=pred\n",
    "    num_classes = cm.shape[0]\n",
    "    eps = 1e-6\n",
    "    tp = np.diag(cm).astype(float)\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    tn = cm.sum() - (tp + fp + fn)\n",
    "    # per-class IoU\n",
    "    iou = tp / (tp + fp + fn + eps)\n",
    "    mean_iou = np.nanmean(iou)\n",
    "    pixel_acc = tp.sum() / (cm.sum() + eps)\n",
    "    # per-class accuracy: tp / (tp + fn)\n",
    "    class_acc = tp / (tp + fn + eps)\n",
    "    mean_acc = np.nanmean(class_acc)\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "    return {\n",
    "        'iou_per_class': iou,\n",
    "        'mean_iou': mean_iou,\n",
    "        'pixel_acc': pixel_acc,\n",
    "        'mean_acc': mean_acc,\n",
    "        'precision_per_class': precision,\n",
    "        'recall_per_class': recall,\n",
    "        'f1_per_class': f1,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Eval loops\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    n = 0\n",
    "    for imgs, masks, _ in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        cm = confusion_matrix_from_logits(logits.detach(), masks.detach())\n",
    "        running_cm += cm\n",
    "        n += imgs.size(0)\n",
    "    avg_loss = running_loss / n\n",
    "    metrics = compute_metrics_from_cm(running_cm)\n",
    "    return avg_loss, metrics['mean_iou']\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_cm = np.zeros((2,2), dtype=np.int64)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, _ in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            running_cm += cm\n",
    "            n += imgs.size(0)\n",
    "    avg_loss = running_loss / n\n",
    "    metrics = compute_metrics_from_cm(running_cm)\n",
    "    return avg_loss, metrics['mean_iou']\n",
    "\n",
    "# -----------------------------\n",
    "# Full evaluation utilities\n",
    "# -----------------------------\n",
    "\n",
    "def evaluate_model_on_test(model, testset, criterion, device):\n",
    "    # As requested, use batch_size = len(testset)\n",
    "    testloader = DataLoader(testset, batch_size=len(testset))\n",
    "    return eval_one_epoch(model, testloader, criterion, device)\n",
    "\n",
    "\n",
    "def detailed_test_evaluation(model, testset, criterion, device, viz_dir=None, per_image_csv=None, overall_image_csv=None, test_orig_sizes=None):\n",
    "    \"\"\"Evaluate overall metrics and per-image metrics + save visualizations.\n",
    "\n",
    "    Adds per-image TP/FP/TN/FN/Total pixel counts (binary positive=class 1),\n",
    "    and per-class IoU values to the per-image CSV.\n",
    "    Also appends aggregate binary counts to the returned overall metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    per_image_rows = []\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, names in testloader:\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks).item()\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            all_cm += cm\n",
    "            m = compute_metrics_from_cm(cm)\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            gt = masks.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            # Save visualization (if requested)\n",
    "            if viz_dir is not None:\n",
    "                save_visualization(imgs.squeeze(0).cpu(), gt, pred, names[0], viz_dir, pred_dir, test_orig_sizes=test_orig_sizes)\n",
    "\n",
    "            # Binary confusion counts for class 1 (debris) vs class 0 (background)\n",
    "            # For 2-class case: TP = cm[1,1], FP = cm[0,1], FN = cm[1,0], TN = cm[0,0]\n",
    "            total_pixels = int(cm.sum())\n",
    "\n",
    "            # per-class IoU\n",
    "            iou_c = m['iou_per_class']\n",
    "            iou_c0 = float(iou_c[0])\n",
    "            iou_c1 = float(iou_c[1])\n",
    "\n",
    "            row = {\n",
    "                'image': names[0],\n",
    "                'loss': loss,\n",
    "                'mIoU': m['mean_iou'],\n",
    "                'pixel_acc': m['pixel_acc'],\n",
    "                'mean_acc': m['mean_acc'],\n",
    "                'iou_class0': iou_c0,\n",
    "                'iou_class1': iou_c1,\n",
    "                'precision_class0': m['precision_per_class'][0],\n",
    "                'precision_class1': m['precision_per_class'][1],\n",
    "                'recall_class0': m['recall_per_class'][0],\n",
    "                'recall_class1': m['recall_per_class'][1],\n",
    "                'f1_class0': m['f1_per_class'][0],\n",
    "                'f1_class1': m['f1_per_class'][1],\n",
    "                'TP': m['tp'],\n",
    "                'FP': m['fp'],\n",
    "                'TN': m['tn'],\n",
    "                'FN': m['fn'],\n",
    "                'Total': total_pixels,\n",
    "            }\n",
    "            per_image_rows.append(row)\n",
    "    \n",
    "    if per_image_csv is not None:\n",
    "        df = pd.DataFrame(per_image_rows)\n",
    "        df.to_csv(per_image_csv, index=False)\n",
    "\n",
    "    overall = compute_metrics_from_cm(all_cm)\n",
    "    # Add aggregate binary counts to the overall metrics for convenience\n",
    "\n",
    "    overall_row = {\n",
    "        'pixel_acc': overall['pixel_acc'],\n",
    "        'mean_acc': overall['mean_acc'],\n",
    "        'iou_class0': float(overall['iou_per_class'][0]),\n",
    "        'iou_class1': float(overall['iou_per_class'][1]),\n",
    "        'precision_class0': overall['precision_per_class'][0],\n",
    "        'precision_class1': overall['precision_per_class'][1],\n",
    "        'recall_class0': overall['recall_per_class'][0],\n",
    "        'recall_class1': overall['recall_per_class'][1],\n",
    "        'f1_class0': overall['f1_per_class'][0],\n",
    "        'f1_class1': overall['f1_per_class'][1],\n",
    "        'TP': overall['tp'],\n",
    "        'FP': overall['fp'],\n",
    "        'TN': overall['tn'],\n",
    "        'FN': overall['fn'],\n",
    "        'Total': int(all_cm.sum()),\n",
    "    }\n",
    "\n",
    "    if overall_image_csv is not None:\n",
    "        df = pd.DataFrame([overall_row])\n",
    "        df.to_csv(overall_image_csv, index=False)\n",
    "\n",
    "    return overall_row, per_image_rows\n",
    "\n",
    "\n",
    "def save_visualization(img_tensor, gt_mask, pred_mask, name, viz_dir, pred_dir, test_orig_sizes={}):\n",
    "    \"\"\"Save side-by-side visualization (Input | GT | Pred) and also save the predicted mask\n",
    "    as a separate grayscale PNG under viz_dir/pred_masks/ with filename <name>_pred_mask.png.\n",
    "    \"\"\"\n",
    "    # img_tensor: normalized tensor; convert back to RGB\n",
    "    img = img_tensor.clone()\n",
    "    img = img * torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "    img = img + torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "    img = img.clamp(0,1).permute(1,2,0).numpy()\n",
    "    gt = gt_mask\n",
    "    pred = pred_mask\n",
    "\n",
    "    # Stack horizontally\n",
    "    fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Input')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(gt, cmap='gray')\n",
    "    axes[1].set_title('GT')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(pred, cmap='gray')\n",
    "    axes[2].set_title('Pred')\n",
    "    axes[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Ensure visualization dir exists and save combined image\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    outpath = os.path.join(viz_dir, f\"{os.path.splitext(name)[0]}_viz.png\")\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Also save predicted mask as a grayscale PNG (0 or 255 values) in 'pred_masks' subdir\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "    # pred may be 0/1; convert to 0/255 uint8\n",
    "    pred_img = (pred.astype(np.uint8) * 255)\n",
    "    pred_pil = Image.fromarray(pred_img, mode='L')\n",
    "    # Determine orig size: precedence argument -> test_orig_sizes mapping\n",
    "    stem = os.path.splitext(name)[0]\n",
    "    if test_orig_sizes is not None:\n",
    "        orig = test_orig_sizes.get(stem, None)\n",
    "        # orig is (H, W)\n",
    "        orig_w = int(orig[1])\n",
    "        orig_h = int(orig[0])\n",
    "        pred_pil = pred_pil.resize((orig_w, orig_h), resample=Image.NEAREST)\n",
    "    pred_out = os.path.join(pred_dir, f\"{stem}_pred_mask.png\")\n",
    "    pred_pil.save(pred_out)\n",
    "\n",
    "# -----------------------------\n",
    "# Plot helpers\n",
    "# -----------------------------\n",
    "\n",
    "def plot_loss(history_csv, outpath):\n",
    "    df = pd.read_csv(history_csv)\n",
    "    plt.figure()\n",
    "    plt.plot(df['epoch'], df['train_loss'], label='train_loss')\n",
    "    plt.plot(df['epoch'], df['val_loss'], label='val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_acc(history_csv, outpath):\n",
    "    df = pd.read_csv(history_csv)\n",
    "    plt.figure()\n",
    "    plt.plot(df['epoch'], df['train_mIoU'], label='train_mIoU')\n",
    "    plt.plot(df['epoch'], df['val_mIoU'], label='val_mIoU')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('mIoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.datetime.now().strftime('%Y%m%d_%H:%M:%S')\n",
    "    # Prepare datasets\n",
    "    train_imgs, train_masks = pair_images_and_masks(train_img_dir, train_mask_dir)\n",
    "    test_imgs, test_masks, test_orig_sizes = pair_test_images_and_masks(test_img_dir, test_mask_dir)\n",
    "    assert len(train_imgs) > 0, 'No training images found'\n",
    "    assert len(test_imgs) > 0, 'No test images found'\n",
    "\n",
    "    # Split train/val if val dirs not provided\n",
    "    if val_img_dir is None or val_mask_dir is None:\n",
    "        n = len(train_imgs)\n",
    "        nval = max(1, int(n * valsplit))\n",
    "        # simple split\n",
    "        val_imgs = train_imgs[:nval]\n",
    "        val_masks = train_masks[:nval]\n",
    "        train_imgs2 = train_imgs[nval:]\n",
    "        train_masks2 = train_masks[nval:]\n",
    "    else:\n",
    "        val_imgs, val_masks = pair_images_and_masks(val_img_dir, val_mask_dir)\n",
    "        train_imgs2, train_masks2 = train_imgs, train_masks\n",
    "\n",
    "    trainset = MyDataset(train_imgs2, train_masks2, img_size=IMG_SIZE)\n",
    "    valset = MyDataset(val_imgs, val_masks, img_size=IMG_SIZE)\n",
    "    testset = MyDataset(test_imgs, test_masks, img_size=IMG_SIZE)\n",
    "\n",
    "    # Dataloaders\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    valloader = DataLoader(valset, batch_size=min(len(valset), batch_size), shuffle=False, num_workers=0)\n",
    "\n",
    "    # Class weights\n",
    "    class_weights, counts, freq = compute_class_weights(trainset)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "    print(f\"Class counts: {counts}, freq: {freq}, weights: {class_weights}\")\n",
    "\n",
    "    # Prepare model (use torchvision's deeplabv3_resnet101)\n",
    "    model = deeplabv3_resnet101(weights=DeepLabV3_ResNet101_Weights.DEFAULT)\n",
    "    # ヘッドを置き換え\n",
    "    model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "    model.aux_classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Loss selection\n",
    "    if loss_type == 'ce':\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    elif loss_type == 'dice':\n",
    "        criterion = DiceLoss()\n",
    "    elif loss_type == 'focal':\n",
    "        alpha = alpha_focal if alpha_focal is not None else class_weights.cpu().numpy().tolist()\n",
    "        criterion = FocalLoss(gamma=gamma_focal, alpha=alpha)\n",
    "    else:\n",
    "        raise ValueError('Unknown loss type')\n",
    "\n",
    "    # Optimizer\n",
    "    if optimizer_type.lower() == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    # History store\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_miou = train_one_epoch(model, trainloader, optimizer, criterion, DEVICE)\n",
    "        val_loss, val_miou = eval_one_epoch(model, valloader, criterion, DEVICE)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, train_mIoU={train_miou:.4f}, val_loss={val_loss:.4f}, val_mIoU={val_miou:.4f}\")\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'train_mIoU': train_miou, 'val_loss': val_loss, 'val_mIoU': val_miou})\n",
    "\n",
    "        # Save every 10 epoch (to support per10-epoch test evaluation).\n",
    "        if epoch % 10 == 0:\n",
    "            model_path = os.path.join(model_dir, f\"{filedate}_epoch{epoch:03d}.pth\")\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Save history to CSV each epoch\n",
    "        df = pd.DataFrame(history)\n",
    "        df.to_csv(history_csv, index=False)\n",
    "\n",
    "    # After training: evaluate all saved epoch models on test set\n",
    "    print('Evaluating saved epoch models on test set...')\n",
    "    model_files = sorted(glob.glob(os.path.join(model_dir, f\"{filedate}_epoch*.pth\")))\n",
    "    per_epoch_results = []\n",
    "    for p in model_files:\n",
    "        state = torch.load(p, map_location=DEVICE)\n",
    "        model.load_state_dict(state)\n",
    "        test_loss, test_miou = evaluate_model_on_test(model, testset, criterion, DEVICE)\n",
    "        per_epoch_results.append({'model_file': os.path.basename(p), 'test_loss': test_loss, 'test_mIoU': test_miou})\n",
    "        print(f\"Model {os.path.basename(p)} -> test_loss={test_loss:.4f}, test_mIoU={test_miou:.4f}\")\n",
    "\n",
    "    per_epoch_df = pd.DataFrame(per_epoch_results)\n",
    "    per_epoch_csv = os.path.join(result_dir, f\"per_10epoch_test_results_{filedate}.csv\")\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    per_epoch_df.to_csv(per_epoch_csv, index=False)\n",
    "\n",
    "    # Select best model by test mIoU\n",
    "    best_row = per_epoch_df.loc[per_epoch_df['test_mIoU'].idxmax()]\n",
    "    best_model_file = os.path.join(model_dir, best_row['model_file'])\n",
    "    print(f\"Best model: {best_model_file} with test_mIoU={best_row['test_mIoU']:.4f}\")\n",
    "    best_epoch = best_row['model_file'].split('_')[-1].split('.')[0]\n",
    "    state = torch.load(best_model_file, map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    # Detailed evaluation with best model\n",
    "    per_image_csv = os.path.join(result_dir, f\"Bestmodel_{best_epoch}_per_image_metrics_{filedate}.csv\")\n",
    "    overall_image_csv = os.path.join(result_dir, f\"Bestmodel_{best_epoch}_overall_image_metrics_{filedate}.csv\")\n",
    "    overall_metrics, per_image_rows = detailed_test_evaluation(\n",
    "        model, testset, criterion, DEVICE, viz_dir=viz_dir, per_image_csv=per_image_csv, overall_image_csv=overall_image_csv, test_orig_sizes=test_orig_sizes)\n",
    "\n",
    "    # Plots\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    plot_loss(history_csv, os.path.join(plots_dir, f\"loss_{filedate}.png\"))\n",
    "    plot_acc(history_csv, os.path.join(plots_dir, f\"acc_{filedate}.png\"))\n",
    "\n",
    "    end_time = datetime.datetime.now().strftime('%Y%m%d_%H:%M:%S')\n",
    "    with open(runinfo_txt, 'w') as f:\n",
    "        f.write(f\"Start: {start_time}\\n\")\n",
    "        f.write(f\"End: {end_time}\\n\")\n",
    "\n",
    "    print('-----TRAINING AND EVALUATION ALL DONE!!!-----')\n",
    "    print('Outputs:')\n",
    "    print(f\" - models: {model_dir}\")\n",
    "    print(f\" - per-epoch test CSV: {per_epoch_csv}\")\n",
    "    print(f\" - best model: {best_model_file}\")\n",
    "    print(f\" - per-image CSV: {per_image_csv}\")\n",
    "    print(f\" - visualizations: {viz_dir}\")\n",
    "    print(f\" - history CSV: {history_csv}\")\n",
    "    print(f\" - plots: {plots_dir}\")\n",
    "    print(f\" - run info: {runinfo_txt}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdff20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record original sizes for test masks and redefine utilities to use them\n",
    "# Builds mapping: stem -> (H, W)\n",
    "test_orig_sizes = {}\n",
    "for p in glob.glob(os.path.join(test_mask_dir, '*')):\n",
    "    stem = os.path.splitext(os.path.basename(p))[0]\n",
    "    try:\n",
    "        with Image.open(p) as im:\n",
    "            w, h = im.size\n",
    "        test_orig_sizes[stem] = (h, w)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def save_visualization(img_tensor, gt_mask, pred_mask, name, viz_dir, pred_dir, orig_size=None):\n",
    "    \"\"\"Save combined visualization and save predicted mask resized to original size (if available).\n",
    "    pred_mask is expected as a numpy array (H_resized, W_resized) with values 0/1.\n",
    "    \"\"\"\n",
    "    # Convert image back to display RGB\n",
    "    img = img_tensor.clone()\n",
    "    img = img * torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "    img = img + torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "    img = img.clamp(0,1).permute(1,2,0).numpy()\n",
    "\n",
    "    gt = gt_mask\n",
    "    pred = pred_mask\n",
    "\n",
    "    # Combined visualization (at resized IMG_SIZE)\n",
    "    fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Input')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(gt, cmap='gray')\n",
    "    axes[1].set_title('GT')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(pred, cmap='gray')\n",
    "    axes[2].set_title('Pred')\n",
    "    axes[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    outpath = os.path.join(viz_dir, f\"{os.path.splitext(name)[0]}_viz.png\")\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Save predicted mask as grayscale PNG in pred_dir, resized to original size if available\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "    pred_img = (pred.astype(np.uint8) * 255)\n",
    "    pred_pil = Image.fromarray(pred_img, mode='L')\n",
    "    # Determine orig size: precedence argument -> test_orig_sizes mapping\n",
    "    stem = os.path.splitext(name)[0]\n",
    "    orig = orig_size if orig_size is not None else test_orig_sizes.get(stem, None)\n",
    "    if orig is not None:\n",
    "        # orig is (H, W)\n",
    "        orig_w = int(orig[1])\n",
    "        orig_h = int(orig[0])\n",
    "        pred_pil = pred_pil.resize((orig_w, orig_h), resample=Image.NEAREST)\n",
    "    pred_out = os.path.join(pred_dir, f\"{stem}_pred_mask.png\")\n",
    "    pred_pil.save(pred_out)\n",
    "\n",
    "\n",
    "# Redefine detailed_test_evaluation to use orig sizes when saving pred masks\n",
    "def detailed_test_evaluation(model, testset, criterion, device, viz_dir=None, per_image_csv=None, overall_image_csv=None):\n",
    "    model.eval()\n",
    "    all_cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    per_image_rows = []\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            imgs = batch[0].to(device)\n",
    "            masks = batch[1].to(device)\n",
    "            names = batch[2]\n",
    "            # orig_size if dataset provides it as 4th item in batch, else lookup from mapping\n",
    "            orig_size = None\n",
    "            if len(batch) > 3:\n",
    "                # batch[3] is a list of orig_size tuples; take first element\n",
    "                orig_size = batch[3][0]\n",
    "            logits = model(imgs)['out'] if isinstance(model(imgs), dict) else model(imgs)\n",
    "            loss = criterion(logits, masks).item()\n",
    "            cm = confusion_matrix_from_logits(logits, masks)\n",
    "            all_cm += cm\n",
    "            m = compute_metrics_from_cm(cm)\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "            gt = masks.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            # Save visualization and predicted mask (resized to orig size)\n",
    "            if viz_dir is not None:\n",
    "                save_visualization(imgs.squeeze(0).cpu(), gt, pred, names[0], viz_dir, pred_dir, orig_size=orig_size)\n",
    "\n",
    "            total_pixels = int(cm.sum())\n",
    "            iou_c = m['iou_per_class']\n",
    "            iou_c0 = float(iou_c[0])\n",
    "            iou_c1 = float(iou_c[1])\n",
    "\n",
    "            row = {\n",
    "                'image': names[0],\n",
    "                'loss': loss,\n",
    "                'mIoU': m['mean_iou'],\n",
    "                'pixel_acc': m['pixel_acc'],\n",
    "                'mean_acc': m['mean_acc'],\n",
    "                'iou_class0': iou_c0,\n",
    "                'iou_class1': iou_c1,\n",
    "                'precision_class0': m['precision_per_class'][0],\n",
    "                'precision_class1': m['precision_per_class'][1],\n",
    "                'recall_class0': m['recall_per_class'][0],\n",
    "                'recall_class1': m['recall_per_class'][1],\n",
    "                'f1_class0': m['f1_per_class'][0],\n",
    "                'f1_class1': m['f1_per_class'][1],\n",
    "                'TP': int(m['tp'].sum()) if hasattr(m['tp'], 'sum') else int(m['tp']),\n",
    "                'FP': int(m['fp'].sum()) if hasattr(m['fp'], 'sum') else int(m['fp']),\n",
    "                'TN': int(m['tn'].sum()) if hasattr(m['tn'], 'sum') else int(m['tn']),\n",
    "                'FN': int(m['fn'].sum()) if hasattr(m['fn'], 'sum') else int(m['fn']),\n",
    "                'Total': total_pixels,\n",
    "            }\n",
    "            per_image_rows.append(row)\n",
    "\n",
    "    if per_image_csv is not None:\n",
    "        df = pd.DataFrame(per_image_rows)\n",
    "        df.to_csv(per_image_csv, index=False)\n",
    "\n",
    "    overall = compute_metrics_from_cm(all_cm)\n",
    "    overall_row = {\n",
    "        'pixel_acc': overall['pixel_acc'],\n",
    "        'mean_acc': overall['mean_acc'],\n",
    "        'iou_class0': float(overall['iou_per_class'][0]),\n",
    "        'iou_class1': float(overall['iou_per_class'][1]),\n",
    "        'precision_class0': overall['precision_per_class'][0],\n",
    "        'precision_class1': overall['precision_per_class'][1],\n",
    "        'recall_class0': overall['recall_per_class'][0],\n",
    "        'recall_class1': overall['recall_per_class'][1],\n",
    "        'f1_class0': overall['f1_per_class'][0],\n",
    "        'f1_class1': overall['f1_per_class'][1],\n",
    "        'TP': int(overall['tp'].sum()) if hasattr(overall['tp'], 'sum') else int(overall['tp']),\n",
    "        'FP': int(overall['fp'].sum()) if hasattr(overall['fp'], 'sum') else int(overall['fp']),\n",
    "        'TN': int(overall['tn'].sum()) if hasattr(overall['tn'], 'sum') else int(overall['tn']),\n",
    "        'FN': int(overall['fn'].sum()) if hasattr(overall['fn'], 'sum') else int(overall['fn']),\n",
    "        'Total': int(all_cm.sum()),\n",
    "    }\n",
    "\n",
    "    if overall_image_csv is not None:\n",
    "        df = pd.DataFrame([overall_row])\n",
    "        df.to_csv(overall_image_csv, index=False)\n",
    "\n",
    "    return overall_row, per_image_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aerial_Photo_Segmenter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
